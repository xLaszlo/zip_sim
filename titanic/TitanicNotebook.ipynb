{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/titanic.db')\n",
    "sqlite_connection = engine.connect()\n",
    "pd.read_sql('SELECT * FROM sqlite_schema WHERE type=\"table\"', con=sqlite_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM tbl_passengers', con=sqlite_connection)\n",
    "\n",
    "targets = pd.read_sql('SELECT * FROM tbl_targets', con=sqlite_connection)\n",
    "\n",
    "# df, targets = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "\n",
    "# parch = Parents/Children, sibsp = Siblings/Spouses\n",
    "df['family_size'] = df['parch'] + df['sibsp']\n",
    "df['is_alone'] = [1 if family_size==1 else 0 for family_size in df['family_size']]\n",
    "\n",
    "df['title'] = [name.split(',')[1].split('.')[0].strip() for name in df['name']]\n",
    "rare_titles = {k for k,v in Counter(df['title']).items() if v < 10}\n",
    "df['title'] = ['rare' if title in rare_titles else title for title in df['title']]\n",
    "\n",
    "df = df[[\n",
    "    'pclass', 'sex', 'age', 'ticket', 'family_size',\n",
    "    'fare', 'embarked', 'is_alone', 'title'\n",
    "]]\n",
    "\n",
    "targets = [int(v) for v in targets['is_survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_categorical = X_train[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
    "X_test_categorical = X_test[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(X_train_categorical)\n",
    "X_train_categorical_one_hot = one_hot_encoder.transform(X_train_categorical)\n",
    "X_test_categorical_one_hot = one_hot_encoder.transform(X_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerical = X_train[['age', 'fare', 'family_size']]\n",
    "X_test_numerical = X_test[['age', 'fare', 'family_size']]\n",
    "knn_imputer = KNNImputer(n_neighbors=5).fit(X_train_numerical)\n",
    "X_train_numerical_imputed = knn_imputer.transform(X_train_numerical)\n",
    "X_test_numerical_imputed = knn_imputer.transform(X_test_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler().fit(X_train_numerical_imputed)\n",
    "X_train_numerical_imputed_scaled = robust_scaler.transform(X_train_numerical_imputed)\n",
    "X_test_numerical_imputed_scaled = robust_scaler.transform(X_test_numerical_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.hstack((X_train_categorical_one_hot, X_train_numerical_imputed_scaled))\n",
    "X_test_processed = np.hstack((X_test_categorical_one_hot, X_test_numerical_imputed_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0).fit(X_train_processed, y_train)\n",
    "y_train_estimation = model.predict(X_train_processed)\n",
    "y_test_estimation = model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, y_train_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, y_test_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(filename, data):\n",
    "    if not os.path.isfile(filename):\n",
    "        pickle.dump(data, open(filename, 'wb'))\n",
    "    truth = pickle.load(open(filename, 'rb'))\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(data, truth)\n",
    "        print(f'{filename} test passed')\n",
    "    except AssertionError as ex:\n",
    "        print(f'{filename} test failed {ex}')\n",
    "    \n",
    "do_test('../data/cm_test.pkl', cm_test)\n",
    "do_test('../data/cm_train.pkl', cm_train)\n",
    "do_test('../data/X_train_processed.pkl', X_train_processed)\n",
    "do_test('../data/X_test_processed.pkl', X_test_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pandas_test(filename, data):\n",
    "    if not os.path.isfile(filename):\n",
    "        data.to_pickle(filename)\n",
    "    truth = pd.read_pickle(filename)\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(data, truth)\n",
    "        print(f'{filename} pandas test passed')\n",
    "    except AssertionError as ex:\n",
    "        print(f'{filename} pandas test failed {ex}')\n",
    "        \n",
    "# df['title'] = ['asd' for v in df['title']]\n",
    "do_pandas_test('../data/df.pkl', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "774712da715a3086605d6bf08e7144a3a7e717b0d5585da12e288357dd4c8f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
